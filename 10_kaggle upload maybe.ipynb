{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0233c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import pandas as pd\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "\n",
    "sub_list=[]\n",
    "for output_id in submission.index:\n",
    "    task_id = output_id.split('_')[0]\n",
    "    pair_id = int(output_id.split('_')[1])\n",
    "    f = str(test_path / str(task_id + '.json'))\n",
    "    with open(f, 'r') as read_file:\n",
    "        task = json.load(read_file)\n",
    "        sub_list.append(task)\n",
    "\n",
    "sub_list\n",
    "\n",
    " \n",
    " ---\n",
    " ---\n",
    "\n",
    "### 1. Create Train - Test - Split\n",
    "\n",
    "def tts(input_list):\n",
    "    Xs_test, ys_test, Xs_train, ys_train = [], [], [], []\n",
    "\n",
    "    for task in input_list:\n",
    "        X_test, y_test, X_train, y_train = [], [], [], []\n",
    "\n",
    "        for pair in task[\"test\"]:\n",
    "            X_test.append(pair[\"input\"])\n",
    "#             y_test.append(pair[\"output\"])      ### to be predicted !!!\n",
    "\n",
    "        for pair in task[\"train\"]:\n",
    "            X_train.append(pair[\"input\"])\n",
    "            y_train.append(pair[\"output\"])\n",
    "\n",
    "        Xs_test.append(X_test)\n",
    "        ys_test.append(y_test)\n",
    "        Xs_train.append(X_train)\n",
    "        ys_train.append(y_train)\n",
    "    return Xs_test, ys_test, Xs_train, ys_train\n",
    "\n",
    " \n",
    "#### Create origanl sized Train-Test-Split for reference \n",
    "\n",
    "Xs_test_orig, ys_test_orig, Xs_train_orig, ys_train_orig = tts(sub_list)\n",
    "\n",
    "len(Xs_train_orig), len(ys_train_orig), len(Xs_test_orig), len(ys_test_orig)\n",
    "\n",
    "len(Xs_train_orig[1]), len(ys_train_orig[1]), len(Xs_test_orig[1]), len(ys_test_orig[1])\n",
    "\n",
    " \n",
    "#### Create actual Train-Test-Split\n",
    "\n",
    "\n",
    "Xs_test, ys_test, Xs_train, ys_train = tts(sub_list)\n",
    "\n",
    "len(Xs_train), len(ys_train), len(Xs_test), len(ys_test)\n",
    "\n",
    "len(Xs_train[1]), len(ys_train[1]), len(Xs_test[1]), len(ys_test[1])\n",
    "\n",
    "## Data Augmentation of the training data\n",
    "\n",
    "# #### color\n",
    "# def color_change(arr):\n",
    "#     x = arr*3\n",
    "# #     x = x/(x.max()+0.1)\n",
    "#     x = np.interp(x, (0.3, 2.7), (0, 0.9))\n",
    "#     x = np.ndarray.round(x,1)\n",
    "#     return x\n",
    "\n",
    "\n",
    "\n",
    "def augm(X_list, y_list):\n",
    "    idx = 1\n",
    "    X_list_new = []\n",
    "    y_list_new = []\n",
    "    \n",
    "    for task_X, task_y in zip(X_list, y_list):\n",
    "        task_li_x = []\n",
    "        task_li_y = []\n",
    "#         print(\"TASK\",idx)\n",
    "        length = len(Xs_train_orig[idx-1])\n",
    "#         print(length)\n",
    "        max_li=[]\n",
    "        for i in range(length):\n",
    "            max_a = max(len(task_X[i]),len(task_X[i][0]))\n",
    "            max_b = max(len(task_y[i]),len(task_y[i][0]))\n",
    "            max_c = max(len(Xs_test[idx-1][0]),len(Xs_test[idx-1][0][0]))\n",
    "#             max_d = max(len(ys_test[idx-1][0]),len(ys_test[idx-1][0][0]))\n",
    "            max_abcd = max(max_a,max_b, max_c)\n",
    "            max_li.append(max_abcd)\n",
    "#             print(f\"max_a = max({len(task_X[i])},{len(task_X[i][0])})\")\n",
    "#             print(f\"max_b = max({len(task_y[i])},{len(task_y[i][0])})\")\n",
    "#             print(max_int)\n",
    "        max_int = max(max_li)\n",
    "            \n",
    "        for e_x,e_y in zip(task_X, task_y):\n",
    "            e_x = (np.array(e_x))/10.     \n",
    "            e_y = (np.array(e_y))/10.\n",
    "#             print(e_x.shape,e_y.shape, max_int)\n",
    "            e_x = np.pad(e_x, [(0, max_int-e_x.shape[0]), (0, max_int-e_x.shape[1])], mode='constant')\n",
    "            e_y = np.pad(e_y, [(0, max_int-e_y.shape[0]), (0, max_int-e_y.shape[1])], mode='constant')\n",
    "#             print(e_x.shape,e_y.shape, max_int, \"\\n\")\n",
    "            task_li_x.append(e_x.reshape(e_x.shape + (1,) ))\n",
    "            task_li_y.append(e_y.reshape(e_y.shape + (1,) ))\n",
    "        # ========================\n",
    "         \n",
    "        while len(task_li_x) < 500*length:    ###################\n",
    "#             print(len(task_li_x))\n",
    "            \"\"\"\n",
    "            choose a random method and append new array\n",
    "            \"\"\"\n",
    "            i = randint(0,length-1) \n",
    "            new_x = (np.array(task_X[i]))/10.\n",
    "#             print((new_x))\n",
    "            new_y = (np.array(task_y[i]))/10.\n",
    "            \n",
    "            \n",
    "            times = randint(1,5)\n",
    "#             print(f\"LENGTH: {len(task_X)} // INDEX: {i} // TIMES: {times}\" )\n",
    "            for j in range(times):\n",
    "                \n",
    "                method = random.choice([np.fliplr, np.flipud, np.rot90])#,color_change])\n",
    "                new_x = method(new_x)\n",
    "                new_y = method(new_y)\n",
    "\n",
    "            new_x = np.pad(new_x, [(0, max_int-new_x.shape[0]), (0, max_int-new_x.shape[1])], mode='constant')\n",
    "\n",
    "            new_y = np.pad(new_y, [(0, max_int-new_y.shape[0]), (0, max_int-new_y.shape[1])], mode='constant')\n",
    "\n",
    "            \n",
    "            task_li_x.append(new_x.reshape(new_x.shape + (1,) ))\n",
    "            task_li_y.append(new_y.reshape(new_y.shape + (1,) ))\n",
    " \n",
    "        X_list_new.append(np.array(task_li_x))\n",
    "        y_list_new.append(np.array(task_li_y))\n",
    "\n",
    "        idx +=1\n",
    "    return     X_list_new, y_list_new\n",
    "\n",
    "Xs_train_aug, ys_train_aug = augm(Xs_train, ys_train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### format test data\n",
    "\n",
    "def t2l(X_list):\n",
    "    li_x =[]\n",
    "#     li_y =[]\n",
    "    idx = 0\n",
    "\n",
    "    for e_x in X_list:\n",
    "        e_x = np.array(e_x[0])\n",
    "#         e_y = np.array(e_y)\n",
    "        max_train = Xs_train_aug[idx].shape[1]\n",
    "        max_int = max(max(e_x.shape),max_train)\n",
    "        print(e_x.shape, max_int)\n",
    "\n",
    "        e_x = np.pad(e_x, [(0, max_int-e_x.shape[0]), (0, max_int-e_x.shape[1])], mode='constant')\n",
    "        e_x = e_x / 10.\n",
    "        e_x = e_x.reshape(e_x.shape + (1,) )\n",
    "#             \n",
    "#         e_y = np.pad(e_y, [(0, max_int-e_y.shape[0]), (0, max_int-e_y.shape[1])], mode='constant')\n",
    "#         e_y = e_y / 10.\n",
    "#         e_y = e_y.reshape(e_y.shape + (1,) )\n",
    "# #             print(e_x.shape, e_y.shape, \"\\n\")\n",
    "        li_x.append(e_x)\n",
    "#         li_y.append(e_y)\n",
    "\n",
    "#         lenght = len(Xs_train_aug[idx])\n",
    "        \n",
    "#         li_x.append([np.array(li2_x)])\n",
    "#         li_y.append([np.array(li2_y)])\n",
    "\n",
    "        idx += 1\n",
    "    return li_x\n",
    "\n",
    "\n",
    "\n",
    "## Model comp\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim, inp_shape, outp_shape, flat_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.inp_shape = inp_shape\n",
    "        self.outp_shape = outp_shape\n",
    "        self.flat_shape = flat_shape\n",
    "        \n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "            layers.Conv2D(160, (3, 3), activation='relu', padding='same', input_shape = inp_shape), #### \n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Conv2D(320, (3, 3), activation='relu', padding='same'),\n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "            layers.Dense(flat_shape, activation='sigmoid'),\n",
    "            layers.Reshape(outp_shape),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "K.clear_session()  \n",
    "latent_dim = 500 \n",
    "idx = 0\n",
    "start = time.time()\n",
    "pred_train_li = []\n",
    "pred_test_li = []\n",
    "\n",
    "for X_train, y_train, X_test, y_test in zip(Xs_train_aug, ys_train_aug, Xs_test_aug, ys_test_aug):\n",
    "    K.clear_session()  \n",
    "#     print(f\"TASK {idx}\")\n",
    "    set_no = 0\n",
    "\n",
    "\n",
    "    ### get input and output shapes to pass to the model\n",
    "    inp_shape = X_train[0].shape\n",
    "#         print('in', inp_shape)\n",
    "    outp_shape = y_train[0].shape#[0]*y_set_train[0].shape[1]\n",
    "#     print('out',outp_shape)\n",
    "    flat_shape = outp_shape[0]*outp_shape[1]\n",
    "#         print('flat',flat_shape)   \n",
    "        \n",
    "        \n",
    "    verb = 0\n",
    "#     if idx%10 == 0: verb=1    \n",
    "    \n",
    "    K.clear_session() \n",
    "    base_model = Autoencoder(latent_dim, inp_shape, outp_shape, flat_shape)\n",
    "\n",
    "    base_model.compile(optimizer='adam', \n",
    "                              loss='mean_squared_error',\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "    callback = keras.callbacks.EarlyStopping(monitor='accuracy',\n",
    "                                                 patience=5)\n",
    "\n",
    "    base_model.fit(X_train, y_train,\n",
    "                          epochs=100,\n",
    "                          batch_size=5000,\n",
    "                          #shuffle=True,\n",
    "                          verbose=verb,\n",
    "                          callbacks=[callback])#,\n",
    "#                           validation_data=(X_set_test, y_set_test))        \n",
    "        \n",
    "    encoded_imgs_train = base_model.encoder(X_train[:1]).numpy()\n",
    "    decoded_imgs_train = base_model.decoder(encoded_imgs_train).numpy()\n",
    "\n",
    "    pred_train = (decoded_imgs_train.reshape(outp_shape[0:2]))*10\n",
    "    \n",
    "    encoded_imgs_test = base_model.encoder(np.array(Xs_test_aug[idx]).reshape((1,)+outp_shape)).numpy()\n",
    "    decoded_imgs_test = base_model.decoder(encoded_imgs_test).numpy()\n",
    "\n",
    "    pred_test = (decoded_imgs_test.reshape(outp_shape[0:2]))*10\n",
    "    \n",
    "    pred_train_li.append(pred_train)\n",
    "    pred_test_li.append(pred_test) \n",
    "        \n",
    "    idx += 1\n",
    "    \n",
    "end = time.time()\n",
    " \n",
    "print(\"Total time: \" + str(np.round(end - start, 1)) + \" s\" + \"\\n\")\n",
    "\n",
    "\n",
    "# base_model.encoder.summary()\n",
    "\n",
    "# base_model.decoder.summary()\n",
    "\n",
    "li=[]\n",
    "for e in pred_test_li:\n",
    "    x = np.rint(e)\n",
    "    x = str(x).replace('.','')\n",
    "    x = x.replace(' ','')\n",
    "    x = x.replace('\\n','')\n",
    "    x = x.replace('[[', '|')\n",
    "    x = x.replace('][', '|')\n",
    "    x = x.replace(']]', '|')\n",
    "#     x_li = x.tolist()\n",
    "#     x_li = flattener(x_li)\n",
    "    li.append(x)\n",
    "\n",
    "\n",
    "pd_series = pd.Series(li)\n",
    "# pd_series\n",
    "\n",
    "# submission = pd.read_csv(data_path / 'sample_submission.csv', index_col='output_id')\n",
    "# submission\n",
    "\n",
    "submission = submission.reset_index()\n",
    "# submission\n",
    "\n",
    "del submission['output']\n",
    "\n",
    "submission['output'] = pd_series\n",
    "\n",
    "submission= submission.set_index(\"output_id\")\n",
    "\n",
    "submission.to_csv('my_submission.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
