{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75706f5c",
   "metadata": {},
   "source": [
    "- augment each pair to N (not every task to 100 (or N*5))\n",
    "- don't resize\n",
    "- fit the model on each expanded set of pairs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57257ab1",
   "metadata": {},
   "source": [
    "NEW NEW NEW\n",
    "- new color definition\n",
    "- reduced amount of times random method is executed\n",
    "- class Autoencoder(Model): included input_shape and output_shape\n",
    "- loooooops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "071f5848",
   "metadata": {},
   "source": [
    " \n",
    "TOMORROOOW:\n",
    "- shapes still don't match up in the model\n",
    "- ideas:\n",
    "    * sth to do with the batch???\n",
    "    * enalrge input to outputsize (resize?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e546464f",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e57bb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random \n",
    "from random import randint\n",
    "import time\n",
    "\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras import backend as K\n",
    "#from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b398b7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path('./kaggle_input/')\n",
    "training_path = data_path / 'training'      # 400 X-train ('train'), y-train('test') input-output pairs\n",
    "evaluation_path = data_path / 'evaluation'  # 400\n",
    "test_path = data_path / 'test'              # 100 pairs X-train ('train') (input-output),\n",
    "                                            #           y-train (input only) pairs\n",
    "\n",
    "training_tasks_files = sorted(os.listdir(training_path))#[1:]\n",
    "eval_tasks_files = sorted(os.listdir(evaluation_path))\n",
    "test_task_files = sorted(os.listdir(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991208ba",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3bb2f0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files(path):\n",
    "    path_files = sorted(os.listdir(path))\n",
    "    tasks = []\n",
    "    for task_file in path_files:\n",
    "        with open(str(path / task_file), 'r') as f:\n",
    "            task = json.load(f)\n",
    "            tasks.append(task)\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279aeed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_tasks = load_files(training_path)          ### this is for building / training the algorithm\n",
    "test_tasks = load_files(test_path)                  ### this is the input for the actual prediction!!!\n",
    "evaluation_tasks = load_files(evaluation_path)      ### testing the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f6281a4a",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,\n",
       " [{'input': [[7, 0, 7], [7, 0, 7], [7, 7, 0]],\n",
       "   'output': [[7, 0, 7, 0, 0, 0, 7, 0, 7],\n",
       "    [7, 0, 7, 0, 0, 0, 7, 0, 7],\n",
       "    [7, 7, 0, 0, 0, 0, 7, 7, 0],\n",
       "    [7, 0, 7, 0, 0, 0, 7, 0, 7],\n",
       "    [7, 0, 7, 0, 0, 0, 7, 0, 7],\n",
       "    [7, 7, 0, 0, 0, 0, 7, 7, 0],\n",
       "    [7, 0, 7, 7, 0, 7, 0, 0, 0],\n",
       "    [7, 0, 7, 7, 0, 7, 0, 0, 0],\n",
       "    [7, 7, 0, 7, 7, 0, 0, 0, 0]]}])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_tasks), training_tasks[0]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b48e1797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,\n",
       " [{'input': [[3, 2], [7, 8]],\n",
       "   'output': [[3, 2, 3, 2, 3, 2],\n",
       "    [7, 8, 7, 8, 7, 8],\n",
       "    [2, 3, 2, 3, 2, 3],\n",
       "    [8, 7, 8, 7, 8, 7],\n",
       "    [3, 2, 3, 2, 3, 2],\n",
       "    [7, 8, 7, 8, 7, 8]]}])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(evaluation_tasks), evaluation_tasks[0]['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "ac0b0577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, [{'input': [[3, 2], [7, 8]]}])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_tasks),test_tasks[0]['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "096f1e84",
   "metadata": {},
   "source": [
    " \n",
    " ---\n",
    " ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d995e2",
   "metadata": {},
   "source": [
    "### 1. Create Train - Test - Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e32dcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tts(input_list):\n",
    "    Xs_test, ys_test, Xs_train, ys_train = [], [], [], []\n",
    "\n",
    "    for task in input_list:\n",
    "        X_test, y_test, X_train, y_train = [], [], [], []\n",
    "\n",
    "        for pair in task[\"test\"]:\n",
    "            X_test.append(pair[\"input\"])\n",
    "            y_test.append(pair[\"output\"])      ### to be predicted !!!\n",
    "\n",
    "        for pair in task[\"train\"]:\n",
    "            X_train.append(pair[\"input\"])\n",
    "            y_train.append(pair[\"output\"])\n",
    "\n",
    "        Xs_test.append(X_test)\n",
    "        ys_test.append(y_test)\n",
    "        Xs_train.append(X_train)\n",
    "        ys_train.append(y_train)\n",
    "    return Xs_test, ys_test, Xs_train, ys_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c92ed",
   "metadata": {},
   "source": [
    " \n",
    "#### Create origanl sized Train-Test-Split for reference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0fe656d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test_orig, ys_test_orig, Xs_train_orig, ys_train_orig = tts(training_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6641f974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 400, 400)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xs_train_orig), len(ys_train_orig), len(Xs_test_orig), len(ys_test_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45e81c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xs_train_orig[0]), len(ys_train_orig[0]), len(Xs_test_orig[0]), len(ys_test_orig[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ddfbd23",
   "metadata": {},
   "source": [
    " \n",
    "#### Create actual Train-Test-Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b7bf53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_test, ys_test, Xs_train, ys_train = tts(training_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf42d0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400, 400, 400, 400)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xs_train), len(ys_train), len(Xs_test), len(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bba84e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 5, 1, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Xs_train[0]), len(ys_train[0]), len(Xs_test[0]), len(ys_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3799718f",
   "metadata": {},
   "source": [
    "## Data Augmentation of the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c44865e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### color\n",
    "def color_change(arr):\n",
    "    x = arr*3\n",
    "#     x = x/(x.max()+0.1)\n",
    "    x = np.interp(x, (0.3, 2.7), (0, 0.9))\n",
    "    x = np.ndarray.round(x,1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c1447c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb5c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augm(X_list, y_list):\n",
    "    start = time.time()\n",
    "    idx = 1\n",
    "    X_list_new = []\n",
    "    y_list_new = []\n",
    "    \n",
    "    for task_X, task_y in zip(X_list, y_list):\n",
    "        print(len(task_X))\n",
    "        task_x_li = []\n",
    "        task_y_li = []\n",
    "        \n",
    "        for e_x, e_y in zip(task_X, task_y):\n",
    "            \n",
    "            new_x = np.array(e_x)     \n",
    "            e_x_li = []\n",
    "            e_x_li.append(new_x.reshape(new_x.shape + (1,) ))\n",
    "            \n",
    "            new_y = np.array(e_y)\n",
    "            e_y_li = []\n",
    "            e_y_li.append(new_y.reshape(new_y.shape + (1,) ))\n",
    "            \n",
    "            while len(e_x_li) < 10:            ###############\n",
    "                \"\"\"\n",
    "                choose a random method and append new array\n",
    "                \"\"\"\n",
    "                times = randint(1,4)\n",
    "                for j in range(times):\n",
    "\n",
    "                    method = random.choice([np.fliplr, np.flipud, np.rot90,color_change])\n",
    "                    new_x = method(new_x)\n",
    "                    new_y = method(new_y)\n",
    "\n",
    "                e_x_li.append(new_x.reshape(new_x.shape + (1,) ))\n",
    "                e_y_li.append(new_y.reshape(new_y.shape + (1,) ))\n",
    "                \n",
    "            task_x_li.append(e_x_li)\n",
    "            task_y_li.append(e_y_li)\n",
    "            \n",
    "        X_list_new.append(task_x_li)\n",
    "        y_list_new.append(task_y_li)\n",
    "            \n",
    "#             idx +=1\n",
    "    end = time.time()\n",
    " \n",
    "    print(\"Total time: \" + str(np.round(end - start, 1)) + \" s\" + \"\\n\")\n",
    "    return X_list_new, y_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "507e92bd",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "6\n",
      "5\n",
      "8\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "7\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "10\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "2\n",
      "3\n",
      "4\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "7\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "4\n",
      "5\n",
      "2\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "7\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "3\n",
      "Total time: 0.9 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train_aug, y_train_aug = augm(Xs_train, ys_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8ea2185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 400)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_aug),len(X_train_aug)   ### number of Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "43b457e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 5)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_aug[0]),len(X_train_aug[0]) ### number of sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e3ac8f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train_aug[0][0]),len(X_train_aug[0][0]) ### number of inputs (pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "524040ba",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0],\n",
       "        [7],\n",
       "        [7]],\n",
       "\n",
       "       [[7],\n",
       "        [7],\n",
       "        [7]],\n",
       "\n",
       "       [[0],\n",
       "        [7],\n",
       "        [7]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_aug[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9af4f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3, 3, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_train_aug[0][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3361c58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e4d916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2096d06f",
   "metadata": {},
   "source": [
    "#### check format of all train test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db4ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xs_train_tasks), type(ys_train_tasks), type(Xs_test_tasks), type(ys_test_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74deeb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xs_train_tasks), len(ys_train_tasks), len(Xs_test_tasks), len(ys_test_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(Xs_train_tasks[0]), type(ys_train_tasks[0]),type(Xs_test_tasks[0]), type(ys_test_tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d790c483",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xs_train_tasks[0]), len(ys_train_tasks[0]),len(Xs_test_tasks[0]), len(ys_test_tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a1ed03",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train_tasks[0][0].shape, ys_train_tasks[0][0].shape,Xs_test_tasks[0][0].shape, ys_test_tasks[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "63e94512",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t2l(split_list):\n",
    "    li =[]\n",
    "    for task in split_list:\n",
    "        task_arr = np.array(task)\n",
    "        li.append(task_arr)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4041883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tf/lib/python3.6/site-packages/ipykernel_launcher.py:4: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "Xs_train_tasks = t2l(X_train_aug)\n",
    "ys_train_tasks = t2l(y_train_aug)\n",
    "Xs_test_tasks = t2l(Xs_test)\n",
    "ys_test_tasks = t2l(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e8452f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, list, list, list)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks), type(ys_train_tasks),type(Xs_test_tasks), type(ys_test_tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9f3ac7c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0]), type(ys_train_tasks[0]),type(Xs_test_tasks[0]), type(ys_test_tasks[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "502e290a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, numpy.ndarray, numpy.ndarray, numpy.ndarray)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0][0]), type(ys_train_tasks[0][0]),type(Xs_test_tasks[0][0]), type(ys_test_tasks[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "40e1733d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " array([[[0.],\n",
       "         [7.],\n",
       "         [7.]],\n",
       " \n",
       "        [[7.],\n",
       "         [7.],\n",
       "         [7.]],\n",
       " \n",
       "        [[0.],\n",
       "         [7.],\n",
       "         [7.]]]))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0][0][0]),Xs_train_tasks[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a69465df",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " array([[0.],\n",
       "        [7.],\n",
       "        [7.]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0][0][0][0]),Xs_train_tasks[0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "52a228f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, array([0.]))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0][0][0][0][0]),Xs_train_tasks[0][0][0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "74c7df65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Xs_train_tasks[0][0][0][0][0][0]),Xs_train_tasks[0][0][0][0][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b907387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs_train_tasks[0][0][0][0][1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd38ddcf",
   "metadata": {},
   "source": [
    "## Model comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d8a60650",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim, inp_shape, outp_shape, flat_shape):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.inp_shape = inp_shape\n",
    "        self.outp_shape = outp_shape\n",
    "        self.flat_shape = flat_shape\n",
    "        \n",
    "        \n",
    "        self.encoder = Sequential([\n",
    "            layers.Conv2D(160, (3, 3), activation='relu', padding='same', input_shape = inp_shape), #### \n",
    "            layers.MaxPooling2D((2, 2), padding='same'),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(latent_dim, activation='relu'),\n",
    "        ])\n",
    "        self.decoder = Sequential([\n",
    "#             layers.InputLayer(input_shape=(latent_dim,)),\n",
    "            layers.Dense(flat_shape, activation='sigmoid'),\n",
    "            layers.Reshape(outp_shape)\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e427dd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5f559292",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK 1\n",
      "(3, 3, 1)\n",
      "out (9, 9, 1)\n",
      "flat 81\n",
      "Epoch 1/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 2.7429 - accuracy: 0.1728"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 9\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-e81bd8948106>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m#                       verbose=0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                           validation_data=(X_set_test, y_set_test))\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                 steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1214\u001b[0m           val_logs = self.evaluate(\n\u001b[1;32m   1215\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1166\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0mnum_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0m_check_data_cardinality\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m     \u001b[0;31m# If batch_size is not passed but steps is, calculate from the input data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_check_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m   1628\u001b[0m           label, \", \".join(str(i.shape[0]) for i in nest.flatten(single_data)))\n\u001b[1;32m   1629\u001b[0m     \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"Make sure all arrays contain the same number of samples.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1630\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 3\n  y sizes: 9\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "K.clear_session()   #clean slate\n",
    "latent_dim = 64 \n",
    "idx = 0\n",
    "#start = time.time()\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "for X_train, y_train, X_test, y_test in zip(Xs_train_tasks, ys_train_tasks,Xs_test_tasks, ys_test_tasks):    \n",
    "    print(\"TASK \" + str(idx + 1))\n",
    "    for X_set_train, y_set_train, X_set_test, y_set_test in zip(X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        ### get input and output shapes to pass to the model\n",
    "        inp_shape = X_set_train[0].shape\n",
    "        print(inp_shape)\n",
    "        outp_shape = y_set_train[0].shape#[0]*y_set_train[0].shape[1]\n",
    "        print('out',outp_shape)\n",
    "        flat_shape = outp_shape[0]*outp_shape[1]\n",
    "        print('flat',flat_shape)\n",
    "        \n",
    "        base_model = Autoencoder(latent_dim, inp_shape, outp_shape, flat_shape)\n",
    "\n",
    "        base_model.compile(optimizer='adam', \n",
    "                              loss='mean_squared_error',\n",
    "                              metrics=['accuracy'])\n",
    "\n",
    "        callback = keras.callbacks.EarlyStopping(monitor='accuracy',\n",
    "                                                 patience=5)\n",
    "\n",
    "        if idx == 0 or idx == 398:\n",
    "            base_model.fit(X_set_train, y_set_train,\n",
    "                          epochs=100,\n",
    "                          batch_size=5000,\n",
    "                          #shuffle=True,\n",
    "    #                       verbose=0,\n",
    "                          callbacks=[callback],\n",
    "                          validation_data=(X_set_test, y_set_test))\n",
    "\n",
    "\n",
    "        else:\n",
    "            base_model.fit(X_set_train, y_set_train,\n",
    "                          epochs=100,\n",
    "                          batch_size=5000,\n",
    "                          #shuffle=True,\n",
    "                          callbacks=[callback],\n",
    "                          verbose=0,\n",
    "                          validation_data=(X_set_test, y_set_test))\n",
    "\n",
    "\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9937e4ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07c6853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "27d827b7",
   "metadata": {},
   "source": [
    "## MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413b3bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = base_model.encoder(Xs_test_tasks[125]).numpy()\n",
    "decoded_imgs = base_model.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e71734",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbc226b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = Xs_test_tasks[125:126][0]#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08afcc20",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576efdea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafdcfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = w*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63951ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = ys_test_tasks[125].reshape(32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cb7648",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa6f02d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y=y*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4558cec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a009daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.predict(w)#.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2573f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = base_model.predict(w).reshape(1,32,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7161fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee14f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=(decoded_imgs[0].reshape(32,32))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ad9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.around(pred,1)*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8efa619",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,15))\n",
    "ax[0].imshow(v[0], cmap=cmap, norm=norm)\n",
    "ax[0].set_title('Train Input')\n",
    "ax[1].imshow(y, cmap=cmap, norm=norm)\n",
    "ax[1].set_title('Train Output')\n",
    "ax[2].imshow(new_arr[0], cmap=cmap, norm=norm)\n",
    "ax[2].set_title('Train Prediction')\n",
    "ax[3].imshow(arr, cmap=cmap, norm=norm)\n",
    "ax[3].set_title('Train Prediction2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d1af36",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "c = 0\n",
    "for task in Xs_train_orig:\n",
    "    i+=1\n",
    "    j = 0\n",
    "    for e in task:\n",
    "        j+=1\n",
    "        c += 1\n",
    "        if c > 124:\n",
    "            break\n",
    "    if c > 124:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5f5178",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa3b306",
   "metadata": {},
   "outputs": [],
   "source": [
    " ww = (np.array(Xs_train_tasks[40][0]).reshape(32,32))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4155d80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ww"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20800ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vv = (np.array(ys_train_tasks[40][0]).reshape(32,32))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725cd3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = ww.reshape(1,32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7078cfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_imgs = base_model.encoder(tt).numpy()\n",
    "decoded_imgs = base_model.decoder(encoded_imgs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d830aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr=(decoded_imgs[0].reshape(32,32))*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe50e832",
   "metadata": {},
   "outputs": [],
   "source": [
    "arr[:10,:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193c9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.asarray(Xs_train_orig[40][0]).shape, np.asarray(ys_train_orig[40][0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7063b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = colors.ListedColormap(\n",
    "            ['#000000', '#0074D9','#FF4136','#2ECC40','#FFDC00',\n",
    "             '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\n",
    "norm = colors.Normalize(vmin=0, vmax=9)\n",
    "fig, ax = plt.subplots(1, 4, figsize=(15,15))\n",
    "ax[0].imshow(ww[:10,:10], cmap=cmap, norm=norm)\n",
    "ax[0].set_title('Train Input')\n",
    "ax[1].imshow(vv[:10,:10], cmap=cmap, norm=norm)\n",
    "ax[1].set_title('Train Output')\n",
    "ax[2].imshow(new_arr[0][:10,:10], cmap=cmap, norm=norm)\n",
    "ax[2].set_title('Train Prediction')\n",
    "ax[3].imshow(arr[:10,:10], cmap=cmap, norm=norm)\n",
    "ax[3].set_title('Train Prediction2');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a53806b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaf975d1",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a363c118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_tasks(split_list):\n",
    "    split_tasks = []\n",
    "    for task in split_list:\n",
    "        li=[]\n",
    "        for e in task:\n",
    "            e = np.array(e)\n",
    "            e = np.pad(e, [(0, 32-e.shape[0]), (0, 32-e.shape[1])], mode='constant')\n",
    "            e = e / 10.\n",
    "            e = e.reshape(e.shape + (1,) )\n",
    "            li.append(e)\n",
    "#         li = np.array(li)\n",
    "        split_tasks.append(li)\n",
    "    return split_tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd7113",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xs_train_tasks = prep_tasks(Xs_train)\n",
    "Xs_test_tasks = prep_tasks(Xs_test)\n",
    "ys_train_tasks = prep_tasks(ys_train)\n",
    "ys_test_tasks = prep_tasks(ys_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0774c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xs_train), len(ys_train), len(Xs_test), len(ys_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c86919e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Xs_train[0]), len(ys_train[0]), len(Xs_test[0]), len(ys_test[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
